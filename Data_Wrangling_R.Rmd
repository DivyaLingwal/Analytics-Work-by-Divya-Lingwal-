---
title: "Assignment_1 Analytics sem1"
output: html_notebook
---


```{r}
library(dplyr)
library(ISLR)
Retail_data <- read.csv("D:/UniversityData/Allstdydata/businessanalytics/Datasets/Online_Retail.csv")

#Show the breakdown of the number of transactions by countries i.e. how many transactions are in the dataset for each country (consider all records including cancelled transactions). Show this in total number and also in percentage. Show only countries accounting for more than 1% of the total transactions.

Retail_data %>% group_by(Country) %>% summarise(nrows=n(),na.rm=FALSE) %>% mutate(total=(nrows/sum(nrows))*100) %>% filter(total,total > 1)
```
```{r}
#	Create a new variable ‘TransactionValue’ that is the product of the exising ‘Quantity’ and ‘UnitPrice’ variables. Add this variable to the dataframe.
Retail_data["Transaction_value"] <- Retail_data$UnitPrice * Retail_data$Quantity
Retail_data
```

```{r}
#	Using the newly created variable, TransactionValue, show the breakdown of transaction values by countries i.e. how much money in total has been spent each country. Show this in total sum of transaction values. Show only countries with total transaction exceeding 130,000 British Pound
Retail_data%>%group_by(Country)%>% summarise(Total_volume=sum(Transaction_value))%>% filter(Total_volume >130000)
```

```{r}
Temp=strptime(Retail_data$InvoiceDate,format='%m/%d/%Y %H:%M',tz='GMT')
Retail_data$New_Invoice_Date <- as.Date(Temp)
Retail_data$New_Invoice_Date[20000]- Retail_data$New_Invoice_Date[10]
Retail_data$Invoice_Day_Week= weekdays(Retail_data$New_Invoice_Date)
Retail_data$New_Invoice_Hour = as.numeric(format(Temp, "%H"))
Retail_data$New_Invoice_Month = as.numeric(format(Temp, "%m"))
```

```{r}
#Which customer had the highest number of transactions? Which customer is most valuable (i.e. highest total sum of transactions)

Retail_data_1 <- na.omit(Retail_data)
Retail_data_1 %>% group_by(CustomerID) %>% summarise(nrows=n()) %>% arrange(desc(nrows)) %>% select(CustomerID,nrows) %>% head(1)
Retail_data_1 %>% group_by(CustomerID) %>% summarise(sum_of_expenditure=sum(Transaction_value)) %>% arrange(desc(sum_of_expenditure)) %>% head(1)
```

```{r}
#Calculate the percentage of missing values for each variable in the dataset 
colMeans(is.na(Retail_data))
```

```{r}
#What are the number of transactions with missing CustomerID records by countries

Retail_data %>% group_by(Country) %>%  filter(is.na(CustomerID)) %>% summarise(total_missing=n()) 
```

```{r}
#On average, how often the costumers comeback to the website for their next shopping? (i.e. what is the average number of days between consecutive shopping)

Retail_data%>% group_by(New_Invoice_Hour) %>% summarise(n=n())
```

```{r}
#Plot the histogram of transaction values from Germany.
hist(Retail_data$Transaction_value[Retail_data$Country=="Germany"]);
```
```{r}
#Which customer had the highest number of transactions? Which customer is most valuable 
Retail_data_1 <- na.omit(Retail_data)
Retail_data_1 %>% group_by(CustomerID) %>% summarise(nrows=n()) %>% arrange(desc(nrows)) %>% select(CustomerID,nrows) %>% head(1)
Retail_data_1 %>% group_by(CustomerID) %>% summarise(sum_of_expenditure=sum(Transaction_value)) %>% arrange(desc(sum_of_expenditure)) %>% head(1)
```
```{r}
# 	Calculate the percentage of missing values for each variable in the dataset 
Retail_data_1 %>% group_by(CustomerID) %>% summarise(sum_of_expenditure=sum(Transaction_value)) %>% arrange(desc(sum_of_expenditure)) %>% head(1)
```

#Calculate the percentage of missing values for each variable in the dataset
```{r}
colMeans(is.na(Retail_data))
```

```{r}
#What are the number of transactions with missing CustomerID records by countries
Retail_data %>% group_by(Country) %>%  filter(is.na(CustomerID)) %>% summarise(total_missing=n()) 
```
```{r}
#On average, how often the costumers comeback to the website for their next shopping? (i.e. what is the average number of days between consecutive #shopping) 
#First we order the dataframe by Custumer ID so that we have all the records for one customer first and then once that is finisheshed we move to the #next Custumer. Then we additionally, sort by the invoice date so for each customer, all the transactions are sorted by date. Now, we use the diff() #function (see here) to compute the delta between the consecutive records. When we move from one customer to another, the date is reset so most #likely we get a negative date delta, also for transactions on the same day, the date delta is zero. We need to filter out delta values equal or #less zero. Then we can compute the mean      

ordered_data<- Retail_data %>% arrange(CustomerID,New_Invoice_Date)
delta_days=diff(ordered_data$New_Invoice_Date,1)
delta_days=delta_days[delta_days>0]
mean(delta_days)
```
```{r}
#In retail sector, it is very important to understand the return rate of the goods purchased by customers. In this example, we can define this quantity, simply, as the ratio of the number of transactions cancelled (regardless of the transaction value) over the total number of transactions. With this definition, what is the return rate for French customers? (10 marks)Consider the cancelled transactions as those where the ‘Quantity’ variable is a negative value.
#As return_rate=(no of cancelled transactions in France/total transactions in France)
library(sqldf)
total_cancelled <- sqldf('SELECT DISTINCT COUNT(InvoiceNo) FROM Retail_data where Quantity<0 and Country="France" ')

Retail_data  %>% filter(Country=="France") %>% summarise(total=n()) %>% mutate(return_rate=(as.numeric(total_cancelled))/total)

```
```{r} 
#What is the product that has generated the highest revenue for the retailer
Retail_data %>% group_by(StockCode) %>% summarise(total=sum(Transaction_value)) %>% arrange(desc(total)) %>% head(1)
```
```{r}
#How many unique customers are represented in the dataset
length(unique(Retail_data$CustomerID))
```


